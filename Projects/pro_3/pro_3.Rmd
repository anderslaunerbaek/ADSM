---
title: 'Advanced Dataanalysis and Statistical Modelling - Assignment 3'
author: "Anders Launer Bæk (s160159)"
date: "`r format(Sys.time(), '%d %B %Y')`"
header-includes: 
    - \usepackage{graphicx}
    - \usepackage{hyperref}
    - \usepackage{amsmath}
output:
  pdf_document: default
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo=FALSE, 
                      include=TRUE,
                      warning=FALSE,
                      fig.width=8, fig.height=4,
                      fig.show='hold', fig.align='center',
                      eval=TRUE, 
                      tidy=TRUE, 
                      dev='pdf', 
                      cache=TRUE, fig.pos="th!")

library(ggplot2)
library(dplyr)
library(nlme)
source('~/DTU/Courses/ADSM/Projects/my_functions.R')
```

```{r include=FALSE}
# get data 
dat <- read.csv(file="~/DTU/Courses/ADSM/Projects/pro_3/data/rats.csv", header = T, sep = "\t") %>% 
  select(-X) %>% 
  mutate(week = ifelse(!is.na(week), week, X.1),
         logw = ifelse(!is.na(logw), logw, X.2),
         rat = as.factor(rat),
         week = as.factor(week)) %>% 
  select(-X.1, -X.2)
n <- dim(dat)[1]
p <- dim(dat)[2]
pretty_n <- 4
```

<!--
- https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1954.sp005141
- 
-->
Sparring partners:

* Andreas Vedel Jantzen (s162858)
* Sana Ahmed (s134649)
* Marie Riis Dammeyer (s134641)

## Q 1.1
The provided data set have `r n` observations which are treated by three different dugs. There area total of `r p` variables. The response variable has the following property:

* `logw` is a non-negative continuous variable with the following statistics: `min=``r round(min(dat$logw), pretty_n)`, `mean=``r round(mean(dat$logw), pretty_n)`, `median=``r round(median(dat$logw), pretty_n)` and `max=``r round(max(dat$logw), pretty_n)`. The variable describes the log-transformed weight of the rat for a given week.

There are three explanatory variables with the following properties:

* `rat` is a nominal categorical variable with `r nlevels(dat$rat)` levels. Each level correspond to a unique rat in the experiment.
* `treatm` is a nominal categorical variable with three levels: `r paste(levels(dat$treatm), collapse = ", ")`. The variable describes the treatment for each rat during the experiment.
* `week` is a nominal categorical variable with five levels: `r paste(levels(dat$week), collapse = ", ")`. The variable describes the week where the `logw` has been measured.

The first step in the exploratory analysis of this report is to report few statistics of rats in the controlled trails, see the output below. 

```{r}
dat %>% mutate(no = n()) %>% 
  group_by(treatm) %>% 
  summarise(no = no[1],
            `No. in treatm` = n(),
            `No. rats` = length(unique(rat)),
            Pct = `No. in treatm` / no * 100) %>% 
  select(-no) %>% 
  knitr::kable(., caption = "\\label{tb_1_0}Percentage distributions within each experiment.")
```

The number of in each of the three different treatments are not equally distributed, see table \ref{tb_1_0}. 
There are three fewer rats in the `Thyroxin` trail and the inequality between numbers of rats needs to be considered during the modelling process.


```{r, eval = FALSE, fig.cap="\\label{fig_1_1}Bar plot of the percentage distribution of rats in the controlled trails."}
dat %>% mutate(no = n()) %>% 
  group_by(treatm) %>% 
  summarise(no = no[1],
            no_treatm = n(),
            rat_no = length(unique(rat)),
            pct = no_treatm / no * 100,
            pct_int = paste(as.integer(pct), "%")) %>% 
  ggplot(., aes(x=treatm, y=pct)) + 
  geom_bar(stat="identity") +
  labs(x = "Treatment", y = "Precentage distribution") +
  coord_flip() + theme_TS() +
  geom_text(aes(label=pct_int), hjust=1, vjust=0, color="white", size=3.5)
```

The reported `summary()`-output (table \ref{tb_1_1}) below shows the selected statistics of the `logw` for each treatment.

```{r}
dat %>%
  group_by(treatm) %>% 
  summarise(`Min.` = min(logw),
            `1st Qu.` = quantile(logw,probs = 0.25),
            Median = median(logw),
            Mean = mean(logw),
            `3rd Qu.` = quantile(logw,probs = 0.75),
            `Max.` = max(logw)) %>% 
  knitr::kable(., caption = "\\label{tb_1_1}Summary() w.r.t. logw.")
```


Figure \ref{fig_1_2} visualizes the statistics of the above `summary()`-output.

```{r, fig.cap="\\label{fig_1_2}Boxplots of the three treatments."}
dat %>% 
  ggplot(., aes(treatm, logw)) + 
  geom_boxplot() + 
  theme_TS() +
  labs(x = "Treatment", y = "(log) Weight")
```

It is not clear to see the effects of the three treatments in the box-plots in figure \ref{fig_1_2} and in table \ref{tb_1_1}. Figure \ref{fig_1_4} shows the average `logw` as a function of week.

```{r, eval=FALSE, fig.cap="\\label{fig_1_3}"}
dat %>%
  ggplot(., aes(x=week, y=logw, colour=treatm)) +
  geom_point() +
  theme_TS() +
  labs(x = "Week", 
       y = "(log) Weigth",
       colour = "")
```

```{r, fig.cap="\\label{fig_1_4}The average log-weigth as a function of week."}
pd <- position_dodge(0.1)
dat %>%
  group_by(week, treatm) %>% 
  summarise(logw_mean = mean(logw),
            logw_sd = sd(logw),
            # logw_se = sd(logw) / sqrt(n()),
            logw_l = logw_mean - logw_sd,
            logw_h = logw_mean + logw_sd) %>% 
ggplot(., aes(x=week, y=logw_mean, 
              colour=treatm, group=treatm)) +
  geom_errorbar(aes(ymin=logw_l, 
                    ymax=logw_h),
                alpha = 0.75, width=1.0, 
                position=pd) +
    geom_line(position=pd, alpha = 0.75) +
    geom_point(position=pd, alpha = 0.75) +
  theme_TS() +
  labs(x = "Week", 
       y = "(log) Weight",
       colour = "Treatment",
       group = "")
```

It has been chosen to add the $\pm$ one standard deviation as "error-bars" to each treatment for each time point in order visualize the dispersion of the `logw` for the rats within each group.
It is possible to see the effects of changes in weight over time for each of the treatments in figure \ref{fig_1_4} which is impossible in figure \ref{fig_1_2} and in table \ref{tb_1_1}.

* The effects of the three treatments are not clear to separate the first two weeks. There is a separation from week three. The `Plain` and the `Thyroxin` follow each other more less to the end of this experiment where the increase in weight are decreasing as a function of weeks for the `Thiouracil` drug. 
* Despite the similar development for the `Plain` and the `Thyroxin` treatment over time. There are a larger dispersion in weight of the rats, which has received the `Thyroxin` drug, in each week.

### Change in weigth as a function of weeks

Table \ref{tb_1_2} reports the similar statistics as table \ref{tb_1_1}, but now with a focus on the change in weight over weeks. 

```{r}
dat %>% 
  tidyr::spread(., week, logw) %>% 
  mutate(`1_to_2` =`2` - `1`,
         `2_to_3` =`3` - `2`,
         `3_to_4` =`4` - `3`,
         `4_to_5` =`5` - `4`) %>% 
  select(-`1`,-`2`,-`3`,-`4`,-`5`) %>% 
  reshape2::melt(., id.vars = c("rat", "treatm"), 
                 variable.name = "week", 
                 value.name = "logw") %>% 
  group_by(treatm) %>% 
  summarise(`Min.` = min(logw),
            `1st Qu.` = quantile(logw,probs = 0.25),
            Median = median(logw),
            Mean = mean(logw),
            `3rd Qu.` = quantile(logw,probs = 0.75),
            `Max.` = max(logw)) %>% 
  knitr::kable(., caption = "\\label{tb_1_2}Summary() w.r.t. the change in logw over time.")
```

The explored patterns of `Plain` and `Thyroxin` drugs, and pattern of `Thiouracil` drug in figure \ref{fig_1_4} is supported by the `summary()` statistics in table \ref{tb_1_2}.

Figure \ref{fig_1_5} visualizes box-plots for each of the treatments. The visual representation of table \ref{tb_1_2} support the explored patterns of `Plain` and `Thyroxin`, and `Thiouracil`.
```{r, fig.cap="\\label{fig_1_5}A visual representation of the statistics in table \\ref{tb_1_2}."}
dat %>% 
  tidyr::spread(., week, logw) %>% 
  mutate(`1_to_2` =`2` - `1`,
         `2_to_3` =`3` - `2`,
         `3_to_4` =`4` - `3`,
         `4_to_5` =`5` - `4`) %>% 
  select(-`1`,-`2`,-`3`,-`4`,-`5`) %>% 
  reshape2::melt(., id.vars = c("rat", "treatm"), 
                 variable.name = "week", 
                 value.name = "logw") %>% 
  ggplot(., aes(treatm, logw)) + 
  geom_boxplot() + 
  theme_TS() +
  labs(x = "Treatment", y = "Change (log) Weight")
```


The final relevant exploratory plot for this data set is the one in figure \ref{fig_1_6}. The plot is combining several box-plots with the $\Delta$`logw` as a function of week for each of the three treatments.

```{r, fig.cap="\\label{fig_1_6}A visual representation of the statistics in table \\ref{tb_1_2}."}
dat_plot <- dat %>% 
  tidyr::spread(., week, logw) %>% 
  mutate(`1_to_2` =`2` - `1`,
         `2_to_3` =`3` - `2`,
         `3_to_4` =`4` - `3`,
         `4_to_5` =`5` - `4`) %>% 
  select(-`1`,-`2`,-`3`,-`4`,-`5`) %>%  
  reshape2::melt(., id.vars = c("rat", "treatm"), 
                 variable.name = "week", 
                 value.name = "logw")

multiplot(
  dat_plot %>% 
  filter(week == "1_to_2") %>% 
  ggplot(., aes(treatm, logw)) + 
  geom_boxplot() + 
  scale_y_continuous(limits = c(0.025, 0.45), breaks = seq(from = 0.025, to = 0.45, by = 0.1)) +
  theme_TS() +
  theme(axis.ticks=element_blank(),
        axis.text.x = element_text(angle = 90)) +
  labs(x = "W1 to W2", y = "Change from week to week (log) Weight"),
dat_plot %>% 
  filter(week == "2_to_3") %>% 
  ggplot(., aes(treatm, logw)) + 
  geom_boxplot() + 
  scale_y_continuous(limits = c(0.025, 0.45)) +
  theme_TS() + 
  theme(axis.text.y=element_blank(), 
        axis.ticks=element_blank(),
        axis.title.y=element_blank(),
        axis.text.x = element_text(angle = 90)) +
  labs(x = "W2 to W3", y = ""),
dat_plot %>% 
  filter(week == "3_to_4") %>% 
  ggplot(., aes(treatm, logw)) + 
  geom_boxplot() + 
  scale_y_continuous(limits = c(0.025, 0.45)) +
  theme_TS() +
  theme(axis.text.y=element_blank(), 
        axis.ticks=element_blank(),
        axis.title.y=element_blank(),
        axis.text.x = element_text(angle = 90)) +
  labs(x = "W3 to W4", y = ""),
dat_plot %>% 
  filter(week == "4_to_5") %>% 
  ggplot(., aes(treatm, logw)) + 
  geom_boxplot() + 
  scale_y_continuous(limits = c(0.025, 0.45)) +
  theme_TS() + 
  theme(axis.text.y=element_blank(), 
        axis.ticks=element_blank(),
        axis.title.y=element_blank(),
        axis.text.x = element_text(angle = 90)) +
  labs(x = "W4 to W5", y = ""),
cols=4)
#
rm(dat_plot)
```

* There is a general decreasing trend in the growth of the weight of the rats as a function of weeks.
* The pattern with similar behavior between the `Plain` and the `Thyroxin` treatments except for the first week. Here is the general trend for `Thyroxin` more restrictive in growth of weight compared to the `Plain` treatment.
* There are two extreme outliers in the first and in the second week for the `Thyroxin` drug. This can identicate that one (or two different) rats get a large restrictive effect wehn reciving the drug.
A through analysis of outliers has not been carried out due to time.
* The `Thiouracil` treatment has the largest restrictive effect of the growth in weight compared to the `Plain` and the `Thyroxin` treatments except for the first week.


\newpage
## Q 1.2

To overcome the possibly high correlation between observations of the same rat is to transform the data set into one observation per rat. This transformation can be done by: `tidyr::spread(dat, week, logw)`-function. Table \ref{tb_1_3} reports the transformed data set.

```{r}
dat_spred <- dat %>% 
  tidyr::spread(., week, logw) %>% 
  mutate(`1_to_2` =`2` - `1`,
         `2_to_3` =`3` - `2`,
         `3_to_4` =`4` - `3`,
         `4_to_5` =`5` - `4`,
         logw_delta =`5` - `1`) %>% 
  select(-`1`,-`2`,-`3`,-`4`,-`5`)

dat_spred %>% 
  knitr::kable(., caption = "\\label{tb_1_3}New independented structure (variable: dat_spred).")
```

The `summary()`-statistics is calculated on the new data set `dat_spred` and reported in table \ref{tb_1_4}.


```{r}
dat_spred %>% 
  group_by(treatm) %>% 
  summarise(`Min.` = min(logw_delta),
            `1st Qu.` = quantile(logw_delta, probs = 0.25),
            Median = median(logw_delta),
            Mean = mean(logw_delta),
            `3rd Qu.` = quantile(logw_delta, probs = 0.75),
            `Max.` = max(logw_delta)) %>% 
  knitr::kable(., caption = "\\label{tb_1_4}Summary() w.r.t. logw\\_delta on new structure (variable: dat_spred).")
```


```{r, eval=FALSE,fig.cap="\\label{fig_1_6}"}
dat_spred %>%
  ggplot(., aes(treatm, logw_delta)) + 
  geom_boxplot() +
  theme_TS() +
  labs(x = "Treatment", y = "Change from W1 to W5 (log) Weight")
```

The new dependency structure w.r.t. treatment and the effect of weight change over the five weeks can be analysed by fitting a simple random effect model. It is assumed that each rat has its own random effect on the change in weight and the response which is will modeled is the total change in weight during the experiment. See the chunk below:
```{r, echo=TRUE}
fit_0 <- lme(logw_delta ~ treatm, random=~1|rat, data=dat_spred, method="ML")
```

Table \ref{tb_1_5} reports the ANOVA-table of the fit. As already ready explored, the `treatm`-variable is significant in order to predict the effect (`logw_delta`) of the three different drugs. 
```{r}
anova(fit_0) %>% 
  knitr::kable(., caption = "\\label{tb_1_5}ANOVA-table of model fit\\_0.")
```

Table \ref{tb_1_6} reports the fixed coefficients of the model `fit_0`.

```{r}
fixed.effects(fit_0) %>% data.frame(.) %>% rename(., Value = `.`)  %>%
  knitr::kable(., caption = "\\label{tb_1_6}Fixed effects of model fit\\_0.")
```

The fixed effect for `Thyroxin` is supposed to be sightly lower than `Plain` and the fixed effect for `Thiouracil` is supposed to be lower than `Plain`. These modeled fixed effects are supported by the plots in figure \ref{fig_1_5} and statistics in table \ref{tb_1_2}.

The random effects can be interpreted as a "latent" variable which not can be observed. The random effects can be extracted by using the `random.effects()`-function and their `summary()`-statistics are reported in table \ref{tb_1_7}. The `visreg()`-function has been applied in order to visualize the random effect from each rat w.r.t. to the estimated model, see figure \ref{fig_1_7}.

The priliminary goal of reporting the statistics of the random effects is to valdiate the underlying assumptions of Gaussianity.

```{r}
data.frame(random.effects(fit_0)) %>% 
  summarise(`Min.` = min(`X.Intercept.`),
            `1st Qu.` = quantile(`X.Intercept.`, probs = 0.25),
            Median = median(`X.Intercept.`),
            Mean = mean(`X.Intercept.`),
            `3rd Qu.` = quantile(`X.Intercept.`, probs = 0.75),
            `Max.` = max(`X.Intercept.`)) %>% 
  knitr::kable(., caption = "\\label{tb_1_7}Summary() w.r.t. the random effects.")
```

```{r, fig.cap="\\label{fig_1_7}Visulizing the random effects for each rat."}
library(visreg)
visreg(fit_0, gg = TRUE, xvar = "rat", by = "treatm") +
  theme_TS() +
  labs(x = "rat", y = "Mean respose + random effects")
```

The random effects forefills the properties of Gaussianity the W.r.t. the reported statistic in table \ref{tb_1_7} and  in the visualization in figure \ref{fig_1_7}.

\newpage

## Q 1.3

### Simple linear mixed model

It has been chosen to use the initial structure of the data set to fit the simple linear mixed model. The fixed effects are `treatm`, `week` and their interaction. The random effect, as earlier discovered, is the rat. The chunk below shows the construction of the simple linear mixed model:

```{r, echo=TRUE}
fit_simple <- lme(logw ~ treatm + week + treatm:week, random=~1|rat,
                  data=dat, method="ML")
```


```{r}
#
coef <- round(summary(fit_simple)$tTable[,"Value"], 4)
#
anova(fit_simple) %>% 
  knitr::kable(., caption = "\\label{tb_1_8}ANOVA-table of model fit\\_simple.")
```

\newpage
The estimated parameters of the simple linear mixed effect model are given in (\ref{eq_1_1}). According to the ANOVA-table (table \ref{tb_1_8}) are all included parameters significantly estimated.

\begin{equation}
\begin{aligned}
Y_i  =& `r paste(coef[1], " \\,+ ", gsub("[:]"," \\\\cdot ", gsub("I[(]|[(]|[)]","",paste("\\\\& ", coef[-1], " \\cdot ", names(coef)[-1], "_{i} \\,+ ", collapse = " "))))` \\ &\beta_i \, + \\ &\epsilon_i
\end{aligned}
\label{eq_1_1}
\end{equation}

where $\beta_i$ is the random effect from each rat ($i = 1,\,2,\,...,\,27$). 

The `summary()`-statistics of the random effects are reported in table \ref{tb_1_9} and the visualization of the random effects w.r.t. to the estimated model is showed in figure \ref{fig_1_8}. Despite the meadian is shilthy positive skewed the properties of Gaussianity is obtained to a high degree.

```{r}
data.frame(random.effects(fit_simple)) %>% 
  summarise(`Min.` = min(`X.Intercept.`),
            `1st Qu.` = quantile(`X.Intercept.`, probs = 0.25),
            Median = median(`X.Intercept.`),
            Mean = mean(`X.Intercept.`),
            `3rd Qu.` = quantile(`X.Intercept.`, probs = 0.75),
            `Max.` = max(`X.Intercept.`)) %>% 
  knitr::kable(., caption = "\\label{tb_1_9}Summary() w.r.t. the random effects.")
```


```{r, fig.cap="\\label{fig_1_8}Visulizing the random effects for each rat."}
visreg(fit_simple, gg = TRUE, xvar = "rat", by = "treatm") +
  theme_TS() +
  #scale_y_continuous(limits = c(0.8, 1.15), breaks = seq(from = 0, to = 2, by = 0.05)) +
  labs(x = "rat", y = "Mean respose + random effects")
```


### log-weight development over time as a second degree polynomial over time

One property of the second degree polynomial model is that the `week`-variable must not be an categorical variable. As illustrated inside the chunk below is has been transformed to a numeric value. Instead of using the `lme()`-function, the `lm()`-function has been applied to fix the new second order polynomial model.

```{r, echo=TRUE}
fit_poly <- dat %>% mutate(week = as.numeric(week)) %>% 
  lm(logw ~ treatm + week + I(week^2) + treatm:week, data=.)
```

```{r}
#
coef <- round(coef(fit_poly), 4)
#
anova(fit_poly) %>% 
  knitr::kable(., caption = "\\label{tb_1_10}ANOVA-table of model fit\\_poly.")
```

The estimated parameters of the second order polynomial model are given in (\ref{eq_1_2}). According to the ANOVA-table (table \ref{tb_1_10}) are all the included parameters significantly predictors.

\begin{equation}
\begin{aligned}
Y_i  =& `r paste(coef[1], " \\,+ ", gsub("[:]"," \\\\cdot ", gsub("I[(]|[(]|[)]","",paste("\\\\& ", coef[-1], " \\cdot ", names(coef)[-1], "_{i} \\,+ ", collapse = " "))))` \\ &\beta_i \, + \\ &\epsilon_i
\end{aligned}
\label{eq_1_2}
\end{equation}

where $\beta_i$ is the random effect from each rat ($i = 1,\,2,\,...,\,27$). 

Figure \ref{fig_1_10} shows the realizations of the three treatments modeled by a second order polynomial model.

```{r, fig.cap="\\label{fig_1_10}Polynominal realizations of the three treatments."}
n_res <- 200
dat_pred <- rbind(data.frame(week = seq(from = 1, to = 5, length.out = n_res),
                             treatm = as.factor(rep("Plain", n_res))),
                  data.frame(week = seq(from = 1, to = 5, length.out = n_res),
                             treatm = as.factor(rep("Thiouracil", n_res))),
                  data.frame(week = seq(from = 1, to = 5, length.out = n_res),
                             treatm = as.factor(rep("Thyroxin", n_res)))) %>% 
  mutate(treatm = as.factor(treatm))
dat_pred$logw <- predict(fit_poly, dat_pred)

# plot 
ggplot(dat ,aes(x=week, y=logw, colour=treatm, group=treatm)) +
  geom_point() +
  geom_line(data = dat_pred, aes(x=week, y=logw, colour=treatm, group=treatm))+
  theme_TS() +
  labs(x = "Week", 
       y = "(log) Weigth",
       colour = "")
```

\newpage

### Comparing mixed effect model and polynominal model

Table \ref{tb_1_12} summaries the selected metrics of the two latter models. 

```{r}
anova(fit_simple, fit_poly, test = FALSE) %>% data.frame(.) %>% select(-call) %>% 
  knitr::kable(., caption = "\\label{tb_1_12}Performance metrics of the two models.")
```

The `fit_simple` model obtain the best metrics w.r.t. the lowest values of `AIC`, `BIC` and the highest value of `logLik`. Thus the higher model complexity (lower value of `df`, the number of degress of freedom, in the model) of the `fit_simple` model, the reported model metrics are still prominent better for the `fit_simple` model.


\newpage

## Q 1.4

The repeated measurement model are given in (\ref{eq_1_3}). It has been chosen to use a Gaussian "spatial" correlation structure ($V_{i_1,\,i_2}$). This should fore fill the a correlation structure where the measurements within each rat is explicitly specified. Furthermore the random effects, of the rats, has been evalutated to be close to Gaussian distributed, see table \ref{tb_1_7} and table \ref{tb_1_9}.

\begin{equation}
\begin{aligned}
Y_i \sim& \mathcal{N}\left( \mu, \,V_{i_1,\,i_2}  \right) \\
\mu  =& \mu + \alpha\left( treatm_i \right) +\beta\left( week_i \right) + \gamma\left( treatm_i,\,week_i \right) \\
V_{i_1,\,i_2} =&\begin{cases}\begin{matrix} 0 & ,\, \, if\, \, week_{ i_{ 1 } }\neq week_{ i_{ 2 } }\, \, and \, \, i_{ 1 }\neq i_{ 2 } \\ v^{ 2 }+\tau^2 \, exp\left\{ \frac { -\left( week_{ i_{ 1 } }-week_{ i_{ 2 } } \right) ^{ 2 } }{ \rho ^{ 2 } }  \right\}  & ,\, \, if\, \, week_{ i_{ 1 } }=week_{ i_{ 2 } }\, \, and\, \, i_{ 1 }\neq i_{ 2 } \\ v^{ 2 }+\tau ^{ 2 }+\sigma ^{ 2 } & ,\,\, if\,\, i_1 = i_2 \end{matrix}   \end{cases}
\end{aligned}
\label{eq_1_3}
\end{equation}
where $v$, $\tau$, $\sigma$ and $\rho$ are parameters which needs to be estimated by the model\footnote{Lecture 9, slide 43-44.}. See the chunk below to see the implementation in R.

```{r, echo = TRUE}
fit_simple_gau <- lme(logw ~ treatm + week + treatm:week, random=~1|rat,
                      correlation=corGaus(form=~as.numeric(week)|rat, nugget=T),
                      data=dat, method="ML")
```


```{r, eval=FALSE}
fit_simple_gau <- lme(logw ~ treatm + week + treatm:week, random=~1|rat,
                      correlation=corGaus(form=~as.numeric(week)|rat, nugget=T),
                      data=dat, method="ML")
fit_simple_exp <- lme(logw ~ treatm + week + treatm:week, random=~1|rat,
                      correlation=corExp(form=~as.numeric(week)|rat, nugget=T),
                      data=dat, method="ML")
fit_simple_comp <- lme(logw ~ treatm + week + treatm:week, random=~1|rat,
                       correlation=corCompSymm(form=~1|rat),
                       data=dat, method="ML")
```

Table \ref{tb_1_13} reports the ANOVA-table of the estimated model `fit_simple_gau`.

```{r}
coef <- round(summary(fit_simple_gau)$tTable[,"Value"], 4)
#
anova(fit_simple_gau) %>% 
  knitr::kable(., caption = "\\label{tb_1_13}ANOVA-table of model fit\\_simple\\_gau.")
```


Figure \ref{fig_1_11} shows a Variogram. The plot visualizes whether the assumption of the chosen correlation structure is correct or not. The chosen correlation structure seems to be suitable.

```{r, fig.cap="\\label{fig_1_11}Variogram of the reapeated measurement model."}
plot(Variogram(fit_simple_gau))
# 
# fit_simple_gau
V_list <- data.frame(v = as.numeric(fit_simple_gau$coefficients$fixed["(Intercept)"]),
                  rho = as.numeric(exp(attr(fit_simple_gau$apVar,"Pars")))[2],
                  nu = as.numeric(exp(attr(fit_simple_gau$apVar,"Pars")))[3],
                  sig = as.numeric(exp(attr(fit_simple_gau$apVar,"Pars")))[4],
                  tau = sqrt(-(as.numeric(exp(attr(fit_simple_gau$apVar,"Pars")))[3]-1)*as.numeric(exp(attr(fit_simple_gau$apVar,"Pars")))[4]^2) / sqrt(as.numeric(exp(attr(fit_simple_gau$apVar,"Pars")))[3]))



```


\newpage
The estimated parameters of the model are given in (\ref{eq_1_4}). According to the ANOVA-table (table \ref{tb_1_13}) are all included parameters significantly predictors.

\begin{equation}
\begin{aligned}
Y_i \sim& \mathcal{N}\left( \mu, \,V_{i_1,\,i_2}  \right) \\
\mu =& `r stringi::stri_sub(paste(coef[1], " \\, + ", gsub("[:]"," \\\\cdot ", gsub("I[(]|[(]|[)]","",paste("\\\\& ", coef[-1], " \\cdot ", names(coef)[-1], "_{i}\\,+ ", collapse = " ")))), to = -5)` \\
%
%
V_{i_1,\,i_2}  =&\begin{cases}\begin{matrix} 0 & ,\, \, if\, \, week_{ i_{ 1 } }\neq week_{ i_{ 2 } } \, \, and \, \, i_{ 1 }\neq i_{ 2 } \\ `r round(V_list$v^2,4)` + `r round(V_list$tau^2,4)` \, exp\left\{ \frac { -\left( week_{ i_{ 1 } }-week_{ i_{ 2 } } \right) ^{ 2 } }{ \rho ^{ 2 } }  \right\}  & ,\, \, if\, \, week_{ i_{ 1 } }=week_{ i_{ 2 } }\, \, and\, \, i_{ 1 }\neq i_{ 2 } \\ `r round(V_list$v^2,4)`+`r round(V_list$tau^2,4)`+`r round(V_list$sig^2,4)` & ,\,\, if\,\, i_1 = i_2 \end{matrix}   \end{cases}
\end{aligned}
\label{eq_1_4}
\end{equation}

where subset $i$ explicitly identicate each rat ($i = 1,\,2,\,...,\,27$). 

The `summary()`-statistics of the random effects are reported in table \ref{tb_1_14} and the visualization of the random effects w.r.t. to the estimated model is showed in figure \ref{fig_1_12}. The is agian positive which can ential a positivly skewed distribution in the random effects which is conflicting with the properties of Gaussianity.

```{r}
data.frame(random.effects(fit_simple_gau)) %>% 
  summarise(`Min.` = min(`X.Intercept.`),
            `1st Qu.` = quantile(`X.Intercept.`, probs = 0.25),
            Median = median(`X.Intercept.`),
            Mean = mean(`X.Intercept.`),
            `3rd Qu.` = quantile(`X.Intercept.`, probs = 0.75),
            `Max.` = max(`X.Intercept.`)) %>% 
  knitr::kable(., caption = "\\label{tb_1_14}Summary() w.r.t. the random effects.")
```


```{r, fig.cap="\\label{fig_1_12}Visulizing the random effects for each rat."}
visreg(fit_simple_gau, gg = TRUE, xvar = "rat", by = "treatm") +
  theme_TS() +
  #scale_y_continuous(limits = c(0.8, 1.15), breaks = seq(from = 0, to = 2, by = 0.05)) +
  labs(x = "rat", y = "Mean respose + random effects")
```


\newpage

## Q 1.5

Few selected model performance metrics of the three previous models (`fit_simple`, `fit_poly` and `fit_simple_gau`) are reported in table \ref{tb_1_15}. 
The least appropriate model is the second order polynomial model `fit_poly`. This model are capable of differentiate between the treatments but not the "hidden" random effects within the rats. The main difference between `fit_simple` and `fit_simple_gau` is the defined correlation structure in `fit_simple_gau`. It is possible to capture the variation of the measurements during the experiment for each rat.

```{r}
anova(fit_simple, fit_poly, fit_simple_gau, test = FALSE) %>% data.frame(.) %>% select(-call) %>% 
  knitr::kable(., caption = "\\label{tb_1_15}Performance metrics of the three models.")
```


The `fit_simple_gau` is the most suitable model for describing the data set.

Trhougput the modelling process of three treatments the following conclusions can be made: 

* The two drugs and the control group have on average same growth patterns.
* After the first two weeks the control group (`Plain`) and the `Thyroxin` drugs follows the same rate. The growth rate of the `Thiouracil` drug is more restrictive to the weight gain of the rats.


<!--
New part.
--> 
\newpage

```{r include=FALSE}
rm(list = ls())
library(nlme)
source('~/DTU/Courses/ADSM/Projects/my_functions.R')
# get data 
dat <- read.csv(file="~/DTU/Courses/ADSM/Projects/pro_3/data/simdat3.csv", header = T, sep = " ") %>% 
  mutate(group = as.factor(group))
n <- dim(dat)[1]
p <- dim(dat)[2]
pretty_n <- 4
```

## Q2.1
The provided data `r n` observations with a total of `r p` variables. The response variable has the following property:

* `y` is a non-negative discrete variable with the following statistics: `min=``r round(min(dat$y), pretty_n)`, `mean=``r round(mean(dat$y), pretty_n)`, `median=``r round(median(dat$y), pretty_n)` and `max=``r round(max(dat$y), pretty_n)`. The variable describes the log-transformed weight of the rat for the given week.

There are three explanatory variables with the following properties:

* `group` is a nominal categorical variable with `r nlevels(dat$group)` levels: `1, 2, ..., 30`. The variable describes the grouping variable.

* `x1` is a non-negative discrete variable with the following statistics: `min=``r round(min(dat$x1), pretty_n)`, `mean=``r round(mean(dat$x1), pretty_n)`, `median=``r round(median(dat$x1), pretty_n)` and `max=``r round(max(dat$x1), pretty_n)`. The variable describes the first regressor.
* `x2` is a non-negative discrete variable with the following statistics: `min=``r round(min(dat$x2), pretty_n)`, `mean=``r round(mean(dat$x2), pretty_n)`, `median=``r round(median(dat$x2), pretty_n)` and `max=``r round(max(dat$x2), pretty_n)`. The variable describes the first regressor.

In further analysis it can be concluded that the two regressors `x1` and `x2` are uniform distributed within the interval `0` to `1`.

```{r, eval=FALSE}
for (ii in 1:30){
  message(ii)
  message(dat %>% filter(group == ii) %>%
  summarise(x1s = sum(x1),
            x2s = sum(x2)))

}
```

Table \ref{tb_2_1} reports the statistics of the response variable `y`. There are `r length(unique(dat$group))` groups within this data set with equally balanced number of observations within each group.

```{r}
dat %>%
  group_by(group) %>% 
  summarise(N = n(),
            `Min.` = min(y),
            `1st Qu.` = quantile(y, probs = 0.25),
            `Median` = median(y),
            `Mean` = mean(y),
            `3rd Qu.` = quantile(y, probs = 0.75),
            `Max.` = max(y)) %>% 
  mutate_if(is.numeric, as.integer) %>% 
  # head(., 5) %>% 
  knitr::kable(., caption = "\\label{tb_2_1}Summary()-statistics of the response variable y for each group.")
```

The `summary()`-statistics of the response shows a different pattern for each group. Figure \ref{fig_2_1} visualize the response as a function of the two regressors. There are ten points in the scatter plot where each point is representing an observation in each group.


```{r, fig.cap="\\label{fig_2_1}Grouping structure of the variables..", fig.asp=1}
dat %>% # filter(group == 1) %>% 
ggplot(., aes(x = x1, y = x2, colour=group, group = group, size = y, label = group)) +
  geom_point(alpha=0.5) +
  # geom_text() +
  labs(x = "x1", y = "x2", color = "Group", size = "Count") +
  theme_TS()
```

```{r, fig.cap="\\label{fig_2_1_1}Grouping structure of the variables..", fig.asp=1}
dat %>%
ggplot(., aes(x = group, y = y, group=group)) +
  geom_point(alpha=0.5) +
  labs(x = "Group", y = "y", color = "Group", size = "Count") +
  theme_TS()
```





This can identicate a certain structure in each group. The group includes the same regressor values but have a different repose strucutre.


\newpage


## Q2.2

Fit a generalized linear model and argue that the grouping structure needs to be taken into account

<!--
todo:
The hierarchical structure arises here from the fact that the so-called first stage model describes the observations given the random effects, and the second stage model is a model for these random effects.
In a general setting mixed models describes dependence between observa- tions within and between groups by assuming the existence of one or more unobserved latent variables for each group of data. The latent variables are assumed to be random and hence referred to as random effects. Hence a mixed model consists of both fixed model parameters θ and random effects U, where the random effects are described by another model and hence another set of parameters describing the assumed distribution for the random effects.
The hierarchical structure of the models implies that the mixed models are a powerful class of models used for the analysis of correlated data. As it will be demonstrated in this chapter, the grouping structure induces a correlation structure of the data even in the classical case of independent data within the groups.
Mixed effects models can handle more general correlation structures than simply correlations between groups. Examples include simple correlation in time between the observations as for time series data; see e.g., Madsen (2008) and problems with missing data.
-->

```{r, echo=TRUE}
fit_glm <- glm(y ~ x1 + x2 + x1:x2, family = poisson(link = "log"), data = dat)
```

```{r, fig.cap="\\label{fig_2_2}"}
res_ana_plot(fit_glm$residuals, fit_glm$fitted.values, x_labs = "Fitted values")
```

```{r,eval=FALSE}

sdreport()
summary(fit_glm,"random")
```


## Q2.3

### Q2.3.1 Write down the model and the estimates, and the interpretation of the parameters


\begin{equation}
\begin{aligned}
1
\end{aligned}
\label{eq_2_1}
\end{equation}


glmmTMB SECOND STAGE MUST BE GAUSSIAN


```{r, echo=TRUE, eval=FALSE}
library(glmmTMB)
fit_TMB <- glmmTMB(formula = y ~ x1 + x2 + group + x1:x2 + x1:group + x2:group + (1|group),
                   family = poisson(link = "log"), data = dat)
```


```{r, eval=FALSE}
summary(fit_TMB) %>% 
  knitr::kable(., caption = "\\label{tb_2_2}Summary()")
```


### Q2.3.2 Plot the estimated random effects in some appropriate way

<!--
todo: RANDOM effects??
-->

The `summary()`-statistics of the random effects are reported in table \ref{tb_2_3} and the visualization of the random effects w.r.t. to the estimated model is showed in figure \ref{fig_1_12}.

```{r, eval=FALSE}
data.frame(random.effects(fit_TMB)) %>% 
  summarise(`Min.` = min(`X.Intercept.`),
            `1st Qu.` = quantile(`X.Intercept.`, probs = 0.25),
            Median = median(`X.Intercept.`),
            Mean = mean(`X.Intercept.`),
            `3rd Qu.` = quantile(`X.Intercept.`, probs = 0.75),
            `Max.` = max(`X.Intercept.`)) %>% 
  knitr::kable(., caption = "\\label{tb_2_3}Summary() w.r.t. the random effects.")
```


```{r, eval=FALSE, fig.cap="\\label{fig_2_3}Visulizing the random effects for each rat."}
visreg(fit_TMB, gg = TRUE, xvar = "rat", by = "treatm") +
  theme_TS() +
  #scale_y_continuous(limits = c(0.8, 1.15), breaks = seq(from = 0, to = 2, by = 0.05)) +
  labs(x = "rat", y = "Mean respose + random effects")
```




### Q2.3.3 Check the accuracy of the Laplace approximation by importance sampling

WHY:

lots of approximations.. 
There is a inaccuracy .. integral vs. laplae transformation..

close to the true interval..

simulate from a distribution -> estimate of the interval


slide 19..


## Q2.4

### Q2.4.1 Write down the model
### Q2.4.2 Estimate parameters and compare with the result in Question 3
### Q2.4.3 Check the accuracy of the Laplace approximation by importance sampling


## Q2.5

### Q2.5.1 Find the explicit formulation of the likelihood (Hint: consult the proof of Theorem 6.1 and the formulation in Theorem 6.3 and Example 6.6, note that the there is a misprint here (U = log(V ) should be V = log(U))).
### Q2.5.2 Implement the above formulation and estimate the parameters.
### Q2.5.3 Find the conditional mean and variance of the random effects (Hint: see (the proof of) Theorem 6.2)

## Q2.6
Compare and discuss the models and estimaton methods you have used in this problem, e.g. which method/model would you prefer, how difficult is it to generalize the results to more complicated structures, etc.
